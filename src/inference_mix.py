import torch
from diffusers import StableDiffusionPipeline
import os

# === 1. é…ç½®è·¯å¾„ ===
base_model = "./sd-v1-5"
lora_dog_path = "./outputs/lora_dog"
lora_sunglasses_path = "./outputs/lora_sunglasses"

# === 2. æç¤ºè¯ (å…³é”®ï¼) ===
# æˆ‘ä»¬åŒæ—¶ä½¿ç”¨äº†ä¸¤ä¸ªè§¦å‘è¯ï¼šsks dog å’Œ sks sunglasses
prompt = "a photo of a sks dog wearing sks sunglasses, in a garden"
negative_prompt = "blur, low quality, distortion, ugly, extra legs"

print("=== ğŸš€ æ­£åœ¨åŠ è½½åº•æ¨¡... ===")
pipe = StableDiffusionPipeline.from_pretrained(
    base_model, 
    torch_dtype=torch.float16,
    safety_checker=None
).to("cuda")

# === 3. åŠ è½½ä¸¤ä¸ª LoRA (é‡ç‚¹) ===
print("=== æ­£åœ¨æ··åˆ LoRA... ===")

# åŠ è½½ç¬¬ä¸€ä¸ªï¼šç‹—
pipe.load_lora_weights(lora_dog_path, adapter_name="dog")

# åŠ è½½ç¬¬äºŒä¸ªï¼šå¢¨é•œ
pipe.load_lora_weights(lora_sunglasses_path, adapter_name="sunglasses")

# æ¿€æ´»ä¸¤ä¸ªé€‚é…å™¨ï¼Œæƒé‡éƒ½è®¾ä¸º 1.0 (ä½ å¯ä»¥å°è¯•è°ƒæ•´è¿™ä¸ªæ¯”ä¾‹ï¼Œæ¯”å¦‚ [0.8, 1.0])
pipe.set_adapters(["dog", "sunglasses"], adapter_weights=[1.0, 1.0])

# === 4. ç”Ÿæˆæµ‹è¯• ===
print(f"=== æ­£åœ¨ç”Ÿæˆ: {prompt} ===")
save_dir = "results/mix_test"
os.makedirs(save_dir, exist_ok=True)

# ç”Ÿæˆ 4 å¼ å›¾çœ‹çœ‹æ•ˆæœ
for i in range(4):
    seed = 2024 + i
    image = pipe(
        prompt, 
        negative_prompt=negative_prompt, 
        num_inference_steps=50, 
        guidance_scale=7.5,
        cross_attention_kwargs={"scale": 1.0}, # å…¨å±€ LoRA å¼ºåº¦
        generator=torch.Generator("cuda").manual_seed(seed)
    ).images[0]
    
    save_path = f"{save_dir}/mix_result_{i}.png"
    image.save(save_path)
    print(f"âœ… å›¾ç‰‡å·²ä¿å­˜: {save_path}")

print("=== ğŸ‰ å®éªŒç»“æŸï¼Œè¯·å»æŸ¥çœ‹ç»“æœï¼ ===")