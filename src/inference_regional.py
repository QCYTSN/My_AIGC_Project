import torch
from diffusers import StableDiffusionPipeline, DDIMScheduler
from PIL import Image, ImageFilter
from torchvision import transforms
import torch.nn.functional as F
import os

# === 1. é…ç½®ä¸åŠ è½½ ===
base_model = "./sd-v1-5"
lora_dog = "./outputs/lora_dog"
lora_glass = "./outputs/lora_sunglasses"
mask_glass_path = "./data/masks/mask_sunglasses.png" 
# æ³¨æ„ï¼šæˆ‘ä»¬åªéœ€è¦å¢¨é•œçš„ maskï¼Œå‰©ä¸‹çš„è‡ªåŠ¨å½’ä¸ºâ€œèƒŒæ™¯/ç‹—â€

# åŠ è½½ Pipeline
pipe = StableDiffusionPipeline.from_pretrained(
    base_model, torch_dtype=torch.float16, safety_checker=None
).to("cuda")

# ä½¿ç”¨ DDIM è°ƒåº¦å™¨
pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)

# åŠ è½½ LoRA
print(">>> ğŸ“¥ åŠ è½½ LoRA...")
pipe.load_lora_weights(lora_dog, adapter_name="dog")
pipe.load_lora_weights(lora_glass, adapter_name="sunglasses")

# === 2. å‡†å¤‡ Mask (äº’æ–¥é€»è¾‘) ===
def load_mask_tensor(path):
    mask = Image.open(path).convert("L").resize((512, 512))
    tensor = transforms.ToTensor()(mask).to("cuda", dtype=torch.float16)
    return tensor.unsqueeze(0) # [1, 1, 512, 512]

# æˆ‘ä»¬åªéœ€è¦åŠ è½½å¢¨é•œçš„ Mask
mask_glass = load_mask_tensor(mask_glass_path)

# âœ¨ æ ¸å¿ƒä¿®æ­£ 1ï¼šæ„å»ºäº’æ–¥ Mask âœ¨
# mask_glass: å¢¨é•œåŒºåŸŸ (1), å…¶ä»–åŒºåŸŸ (0)
# mask_bg: å…¶ä»–åŒºåŸŸ (1), å¢¨é•œåŒºåŸŸ (0) --> è¿™ä¸ªåŒºåŸŸç”¨æ¥ç”»ç‹—å’ŒèƒŒæ™¯
mask_bg = 1.0 - mask_glass

# === 3. å‡†å¤‡ Embeddings ===
def get_embeds(prompt):
    inputs = pipe.tokenizer(prompt, padding="max_length", max_length=pipe.tokenizer.model_max_length, truncation=True, return_tensors="pt")
    return pipe.text_encoder(inputs.input_ids.to("cuda"))[0]

neg_embeds = get_embeds("blur, low quality, distortion, ugly, bad anatomy") 
# å¹³è¡Œä¸–ç•Œ A (èƒŒæ™¯+ç‹—): 
embeds_dog = get_embeds("a photo of a sks dog in a garden, high quality, 8k")
# å¹³è¡Œä¸–ç•Œ B (å¢¨é•œ):
embeds_glass = get_embeds("a photo of a sks sunglasses, transparent glass, highly detailed, close up")

# === 4. æ‰‹å†™ç”Ÿæˆå¾ªç¯ ===
print(">>> ğŸš€ å¼€å§‹åŒºåŸŸåŒ–ç”Ÿæˆ (ä¿®å¤ç‰ˆ)...")

# åˆå§‹åŒ–éšæœºå™ªå£°
latents = torch.randn((1, 4, 64, 64), device="cuda", dtype=torch.float16)

# âœ¨ æ ¸å¿ƒä¿®æ­£ 2ï¼šç¼©æ”¾åˆå§‹å™ªå£° (é˜²æ­¢ç”µè§†é›ªèŠ±çš„å…³é”®ï¼) âœ¨
latents = latents * pipe.scheduler.init_noise_sigma

pipe.scheduler.set_timesteps(50)

with torch.no_grad():
    for t in pipe.scheduler.timesteps:
        # --- ä¸–ç•Œ A: ç‹— + èƒŒæ™¯ ---
        pipe.set_adapters(["dog"], adapter_weights=[1.0])
        
        input_cat = torch.cat([latents] * 2)
        input_cat = pipe.scheduler.scale_model_input(input_cat, t) # ç¼©æ”¾è¾“å…¥
        embeds_cat = torch.cat([neg_embeds, embeds_dog])
        
        noise_pred_A = pipe.unet(input_cat, t, encoder_hidden_states=embeds_cat).sample
        noise_uncond, noise_text_A = noise_pred_A.chunk(2)
        noise_pred_A = noise_uncond + 7.5 * (noise_text_A - noise_uncond)

        # --- ä¸–ç•Œ B: å¢¨é•œ ---
        pipe.set_adapters(["sunglasses"], adapter_weights=[1.0])
        
        input_cat = torch.cat([latents] * 2)
        input_cat = pipe.scheduler.scale_model_input(input_cat, t)
        embeds_cat = torch.cat([neg_embeds, embeds_glass])
        
        noise_pred_B = pipe.unet(input_cat, t, encoder_hidden_states=embeds_cat).sample
        noise_uncond, noise_text_B = noise_pred_B.chunk(2)
        noise_pred_B = noise_uncond + 7.5 * (noise_text_B - noise_uncond)

        # --- èåˆ ---
        # ç¼©å° Mask åˆ° Latent å°ºå¯¸
        mask_glass_small = F.interpolate(mask_glass, size=(64, 64), mode="nearest")
        mask_bg_small = 1.0 - mask_glass_small # ç¡®ä¿æ— ç¼è¡”æ¥
        
        # æ‹¼æ¥å™ªå£°: (ç‹—å™ªå£° * ç‹—åŒºåŸŸ) + (å¢¨é•œå™ªå£° * å¢¨é•œåŒºåŸŸ)
        merged_noise = (noise_pred_A * mask_bg_small) + (noise_pred_B * mask_glass_small)
        
        # æ›´æ–° Latents
        latents = pipe.scheduler.step(merged_noise, t, latents).prev_sample

# === 5. è§£ç å¹¶ä¿å­˜ ===
print(">>> ğŸ–¼ï¸ è§£ç å›¾åƒ...")
image = pipe.vae.decode(latents / pipe.vae.config.scaling_factor, return_dict=False)[0]
# âœ¨ æ ¸å¿ƒä¿®æ­£ 3: è§£é™¤æ¢¯åº¦é”
image = image.detach()
image = pipe.image_processor.postprocess(image, output_type="pil", do_denormalize=[True])[0]

save_path = "results/regional_result_fixed.png"
image.save(save_path)
print(f"âœ… æˆåŠŸï¼ç»“æœä¿å­˜åœ¨ {save_path}")