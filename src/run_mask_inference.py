import torch
from PIL import Image
from torchvision import transforms
from pipeline_mask import MaskStableDiffusionPipeline # å¼•å…¥åˆšæ‰å†™å¥½çš„ Pipeline
import os

# === 1. å‡†å¤‡è·¯å¾„ ===
base_model = "./sd-v1-5"
lora_dog = "./outputs/lora_dog"
lora_glass = "./outputs/lora_sunglasses"
mask_dog_path = "./data/masks/mask_dog.png"
mask_glass_path = "./data/masks/mask_sunglasses.png"

prompt = "a photo of a sks dog wearing sks sunglasses"
# âš ï¸ æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç®€åŒ–äº†å•è¯åŒ¹é…ï¼Œç¡®ä¿ mask çš„ key (æ¯”å¦‚ "dog") èƒ½åœ¨ prompt é‡Œæ‰¾åˆ°

# === 2. åŠ è½½ Pipeline ===
print(">>> ğŸš€ åŠ è½½ Mask Pipeline...")
pipe = MaskStableDiffusionPipeline.from_pretrained(
    base_model, 
    torch_dtype=torch.float16,
    safety_checker=None
).to("cuda")

# åŠ è½½ LoRA
print(">>> ğŸ“¥ åŠ è½½åŒ LoRA...")
pipe.load_lora_weights(lora_dog, adapter_name="dog")
pipe.load_lora_weights(lora_glass, adapter_name="sunglasses")
pipe.set_adapters(["dog", "sunglasses"], adapter_weights=[1.0, 1.0])

# === 3. å‡†å¤‡ Masks ===
# æˆ‘ä»¬éœ€è¦æŠŠå›¾ç‰‡å˜æˆ Tensor (1, 1, 512, 512)
def load_mask(path):
    mask = Image.open(path).convert("L") # è½¬é»‘ç™½
    mask = mask.resize((512, 512))
    tensor = transforms.ToTensor()(mask) # å˜æˆ [0, 1] çš„ tensor
    tensor = tensor.unsqueeze(0) # [1, 1, 512, 512]
    return tensor

mask_config = {
    "dog": load_mask(mask_dog_path),
    "sunglasses": load_mask(mask_glass_path)
}

# === 4. ç”Ÿæˆ ===
print(f">>> ğŸ¨ å¼€å§‹ç”Ÿæˆ: {prompt}")
output_dir = "results/mask_test"
os.makedirs(output_dir, exist_ok=True)

for i in range(4):
    seed = 2024 + i
    image = pipe(
        prompt=prompt,
        mask_config=mask_config, # <--- ä¼ å…¥æˆ‘ä»¬çš„ Mask é…ç½®
        num_inference_steps=50,
        guidance_scale=7.5,
        generator=torch.Generator("cuda").manual_seed(seed)
    ).images[0]
    
    save_path = f"{output_dir}/mask_result_{i}.png"
    image.save(save_path)
    print(f"âœ… ä¿å­˜ç»“æœ: {save_path}")

print(">>> ğŸ‰ å®éªŒç»“æŸï¼å¿«å» results/mask_test çœ‹çœ‹æœ‰æ²¡æœ‰å¥‡è¿¹å‘ç”Ÿï¼")